{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385a4919",
   "metadata": {},
   "source": [
    "# 1. fewshot template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e68f125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ğŸ¦œ 9 è¿™ä¸ªè¡¨è¾¾å¼çš„æ„æ€ä¸å¤ªæ˜ç¡®ã€‚å¦‚æœä½ èƒ½æä¾›æ›´å¤šçš„ä¸Šä¸‹æ–‡æˆ–è§£é‡Šâ€œğŸ¦œâ€çš„å«ä¹‰ï¼Œæˆ‘ä¼šå¾ˆä¹æ„å¸®åŠ©ä½ è¿›è¡Œè®¡ç®—æˆ–è§£ç­”ã€‚\n"
     ]
    }
   ],
   "source": [
    "# 1. æ— æ¡ˆä¾‹çš„æ˜¯æ—¶å€™çš„å›ç­”\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_core.prompts import FewShotPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\",\n",
    "                        temperature=0.4)\n",
    "\n",
    "res = chat_model.invoke(\"2 ğŸ¦œ 9æ˜¯å¤šå°‘?\")\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c647d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¸Šæµ·å¸‚\n"
     ]
    }
   ],
   "source": [
    "# 2. å®ä¾‹çš„è°ƒç”¨\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "example_prompt =PromptTemplate.from_template(\n",
    "  # æ³¨æ„è¿™é‡Œå’Œexampleé‡Œé¢æ˜¯å¯¹åº”çš„\n",
    "  template=\"input: {input}\\noutput: {output}\"\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·\", \"output\": \"åŒ—äº¬å¸‚\"},\n",
    "    {\"input\": \"å—äº¬ä¸‹é›¨å—\", \"output\": \"å—äº¬å¸‚\"},\n",
    "    {\"input\": \"æ­¦æ±‰çƒ­å—\", \"output\": \"æ­¦æ±‰å¸‚\"}\n",
    "]\n",
    "\n",
    "# åˆ›å»ºfew shot prompt\n",
    "few_shot_template = FewShotPromptTemplate(\n",
    "  example_prompt = example_prompt,\n",
    "  examples = examples,\n",
    "  # å£°æ˜åœ¨ç¤ºä¾‹åé¢çš„æç¤ºè¯æ¨¡æ¿\n",
    "  suffix = \"input: {input}\\noutput:\",\n",
    "  input_variables = [\"input\"],\n",
    "\n",
    ")\n",
    "\n",
    "a_template = few_shot_template.invoke({\"input\": \"ä¸Šæµ·å¤©æ°”æ€ä¹ˆæ ·\"})\n",
    "response = chat_model.invoke(a_template)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad3826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ä¸¾ä¾‹3\n",
    "#1ã€åˆ›å»ºæç¤ºæ¨¡æ¿\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# åˆ›å»ºæç¤ºæ¨¡æ¿ï¼Œé…ç½®ä¸€ä¸ªæç¤ºæ¨¡æ¿ï¼Œå°†ä¸€ä¸ªç¤ºä¾‹æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²\n",
    "prompt_template = \"ä½ æ˜¯ä¸€ä¸ªæ•°å­¦ä¸“å®¶,ç®—å¼ï¼š {input} å€¼ï¼š {output} ä½¿ç”¨ï¼š {description} \"\n",
    "\n",
    "# è¿™æ˜¯ä¸€ä¸ªæç¤ºæ¨¡æ¿ï¼Œç”¨äºè®¾ç½®æ¯ä¸ªç¤ºä¾‹çš„æ ¼å¼\n",
    "prompt_sample = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "#2ã€æä¾›ç¤ºä¾‹\n",
    "examples = [\n",
    "    {\"input\": \"2+2\", \"output\": \"4\", \"description\": \"åŠ æ³•è¿ç®—\"},\n",
    "    {\"input\": \"5-2\", \"output\": \"3\", \"description\": \"å‡æ³•è¿ç®—\"},\n",
    "]\n",
    "\n",
    "\n",
    "#3ã€åˆ›å»ºä¸€ä¸ªFewShotPromptTemplateå¯¹è±¡\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=prompt_sample,\n",
    "    suffix=\"ä½ æ˜¯ä¸€ä¸ªæ•°å­¦ä¸“å®¶,ç®—å¼: {input}  å€¼: {output}\",\n",
    "    input_variables=[\"input\", \"output\"]\n",
    ")\n",
    "# print(prompt.invoke({\"input\":\"2*5\", \"output\":\"10\"}))\n",
    "\n",
    "#4ã€åˆå§‹åŒ–å¤§æ¨¡å‹ï¼Œç„¶åè°ƒç”¨\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY1\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "result = chat_model.invoke(prompt.invoke({\"input\":\"2*5\", \"output\":\"10\"}))\n",
    "print(result.content)  # ä½¿ç”¨: ä¹˜æ³•è¿ç®—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be01c0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç®—å¼ï¼š 2 * 5  \n",
      "å€¼ï¼š 10  \n",
      "ä½¿ç”¨ï¼š ä¹˜æ³•è¿ç®—\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import FewShotPromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template1 = PromptTemplate.from_template(\n",
    "  template=\"ä½ æ˜¯ä¸€åæ•°å­¦ä¸“å®¶ï¼Œç®—å¼ï¼š {input} å€¼ï¼š {output} ä½¿ç”¨ï¼š {description} \",\n",
    ")\n",
    "\n",
    "examples =[\n",
    "    {\"input\": \"2+2\", \"output\": \"4\", \"description\": \"åŠ æ³•è¿ç®—\"},\n",
    "    {\"input\": \"5-2\", \"output\": \"3\", \"description\": \"å‡æ³•è¿ç®—\"},\n",
    "]\n",
    "\n",
    "few_shot_template1 = FewShotPromptTemplate(\n",
    "  example_prompt = prompt_template1,\n",
    "  examples = examples,\n",
    "  # è¿™é‡Œè¯´æ˜suffixè¿™ä¸ªåœ°æ–¹ï¼Œè¾“å…¥å’Œinputåº”è¯¥æ˜¯è¦åŒ¹é…çš„ï¼Œè€Œä¸”æ ¼å¼åŒ–çš„æ—¶å€™ï¼Œè¦æŠŠinputå’Œoutputéƒ½ä¼ è¿›å»,ä¼ å¤šä¼ å°‘éƒ½ä¼šæŠ¥é”™ï¼Œå…³é”®æ˜¯è¦çœ‹ä½ çš„formatæˆ–è€…invokeéœ€è¦ä¼ å…¥å“ªäº›\n",
    "  suffix = \"ä½ æ˜¯ä¸€åæ•°å­¦ä¸“å®¶ï¼Œç®—å¼ï¼š {input}\",\n",
    "  input_variables = [\"input\"],\n",
    ")\n",
    "\n",
    "# few_shot_template1.invoke({\"input\": \"2*5\", \"output\": \"10\"})\n",
    "from langchain_openai import ChatOpenAI\n",
    "chat_model1 = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "result1 = chat_model1.invoke(few_shot_template1.invoke({\"input\": \"2*5\"}))\n",
    "print(result1.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75eb5de",
   "metadata": {},
   "source": [
    "# 2. fewshotChatMessageTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526a0301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    FewShotChatMessagePromptTemplate,\n",
    "    ChatPromptTemplate\n",
    ")\n",
    "\n",
    "# 1.ç¤ºä¾‹æ¶ˆæ¯æ ¼å¼\n",
    "examples = [\n",
    "    {\"input\": \"1+1ç­‰äºå‡ ï¼Ÿ\", \"output\": \"1+1ç­‰äº2\"},\n",
    "    {\"input\": \"æ³•å›½çš„é¦–éƒ½æ˜¯ï¼Ÿ\", \"output\": \"å·´é»\"}\n",
    "]\n",
    "\n",
    "# 2.å®šä¹‰ç¤ºä¾‹çš„æ¶ˆæ¯æ ¼å¼æç¤ºè¯æ¨¡ç‰ˆ\n",
    "msg_example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"{output}\"),\n",
    "])\n",
    "\n",
    "# 3.å®šä¹‰FewShotChatMessagePromptTemplateå¯¹è±¡\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=msg_example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "# 4.è¾“å‡ºæ ¼å¼åŒ–åçš„æ¶ˆæ¯\n",
    "print(few_shot_prompt.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4786653e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2ğŸ¦œ10 ç­‰äº 1024ã€‚'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.å¯¼å…¥ç›¸å…³åŒ…\n",
    "from langchain_core.prompts import (FewShotChatMessagePromptTemplate, ChatPromptTemplate)\n",
    "\n",
    "# 2.å®šä¹‰ç¤ºä¾‹ç»„\n",
    "examples = [\n",
    "    {\"input\": \"2ğŸ¦œ3\", \"output\": \"8\"},\n",
    "    {\"input\": \"2ğŸ¦œ4\", \"output\": \"16\"},\n",
    "]\n",
    "\n",
    "# 3.å®šä¹‰ç¤ºä¾‹çš„æ¶ˆæ¯æ ¼å¼æç¤ºè¯æ¨¡ç‰ˆ\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('human', '{input} æ˜¯å¤šå°‘?'),\n",
    "    ('ai', '{output}')\n",
    "])\n",
    "\n",
    "# 4.å®šä¹‰FewShotChatMessagePromptTemplateå¯¹è±¡\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    examples=examples,  # ç¤ºä¾‹ç»„\n",
    "    example_prompt=example_prompt,  # ç¤ºä¾‹æç¤ºè¯è¯æ¨¡ç‰ˆ\n",
    ")\n",
    "# 5.è¾“å‡ºå®Œæ•´æç¤ºè¯çš„æ¶ˆæ¯æ¨¡ç‰ˆ\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', 'ä½ æ˜¯ä¸€ä¸ªæ•°å­¦å¥‡æ‰'),\n",
    "        few_shot_prompt,\n",
    "        ('human', '{input}'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#6.æä¾›å¤§æ¨¡å‹\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\",\n",
    "                        temperature=0.4)\n",
    "\n",
    "chat_model.invoke(final_prompt.invoke(input=\"2ğŸ¦œ10\")).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c65ba91",
   "metadata": {},
   "source": [
    "# 3. ç¤ºä¾‹é€‰æ‹©å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28112c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¸è¾“å…¥æœ€ç›¸ä¼¼çš„ç¤ºä¾‹ï¼š[{'question': 'è°æ˜¯ä¹”æ²»Â·åç››é¡¿çš„å¤–ç¥–çˆ¶ï¼Ÿ', 'answer': '\\n        æ¥ä¸‹æ¥è¿˜éœ€è¦é—®ä»€ä¹ˆé—®é¢˜å—ï¼Ÿ\\n        è¿½é—®ï¼šè°æ˜¯ä¹”æ²»Â·åç››é¡¿çš„æ¯äº²ï¼Ÿ\\n        ä¸­é—´ç­”æ¡ˆï¼šä¹”æ²»Â·åç››é¡¿çš„æ¯äº²æ˜¯ç›ä¸½Â·é²å°”Â·åç››é¡¿ã€‚\\n        '}]\n"
     ]
    }
   ],
   "source": [
    "# 1.å¯¼å…¥ç›¸å…³åŒ…\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "# 3.å®šä¹‰ç¤ºä¾‹ç»„\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"è°æ´»å¾—æ›´ä¹…ï¼Œç©†ç½•é»˜å¾·Â·é˜¿é‡Œè¿˜æ˜¯è‰¾ä¼¦Â·å›¾çµ?\",\n",
    "        \"answer\": \"\"\"\n",
    "        æ¥ä¸‹æ¥è¿˜éœ€è¦é—®ä»€ä¹ˆé—®é¢˜å—ï¼Ÿ\n",
    "        è¿½é—®ï¼šç©†ç½•é»˜å¾·Â·é˜¿é‡Œå»ä¸–æ—¶å¤šå¤§å¹´çºªï¼Ÿ\n",
    "        ä¸­é—´ç­”æ¡ˆï¼šç©†ç½•é»˜å¾·Â·é˜¿é‡Œå»ä¸–æ—¶äº«å¹´74å²ã€‚\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"craigslistçš„åˆ›å§‹äººæ˜¯ä»€ä¹ˆæ—¶å€™å‡ºç”Ÿçš„ï¼Ÿ\",\n",
    "        \"answer\": \"\"\"\n",
    "        æ¥ä¸‹æ¥è¿˜éœ€è¦é—®ä»€ä¹ˆé—®é¢˜å—ï¼Ÿ\n",
    "        è¿½é—®ï¼šè°æ˜¯craigslistçš„åˆ›å§‹äººï¼Ÿ\n",
    "        ä¸­çº§ç­”æ¡ˆï¼šCraigslistæ˜¯ç”±å…‹é›·æ ¼Â·çº½é©¬å…‹åˆ›ç«‹çš„ã€‚\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"è°æ˜¯ä¹”æ²»Â·åç››é¡¿çš„å¤–ç¥–çˆ¶ï¼Ÿ\",\n",
    "        \"answer\": \"\"\"\n",
    "        æ¥ä¸‹æ¥è¿˜éœ€è¦é—®ä»€ä¹ˆé—®é¢˜å—ï¼Ÿ\n",
    "        è¿½é—®ï¼šè°æ˜¯ä¹”æ²»Â·åç››é¡¿çš„æ¯äº²ï¼Ÿ\n",
    "        ä¸­é—´ç­”æ¡ˆï¼šä¹”æ²»Â·åç››é¡¿çš„æ¯äº²æ˜¯ç›ä¸½Â·é²å°”Â·åç››é¡¿ã€‚\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"ã€Šå¤§ç™½é²¨ã€‹å’Œã€Šçš‡å®¶èµŒåœºã€‹çš„å¯¼æ¼”éƒ½æ¥è‡ªåŒä¸€ä¸ªå›½å®¶å—ï¼Ÿ\",\n",
    "        \"answer\": \"\"\"\n",
    "        æ¥ä¸‹æ¥è¿˜éœ€è¦é—®ä»€ä¹ˆé—®é¢˜å—ï¼Ÿ\n",
    "        è¿½é—®ï¼šã€Šå¤§ç™½é²¨ã€‹çš„å¯¼æ¼”æ˜¯è°ï¼Ÿ\n",
    "        ä¸­çº§ç­”æ¡ˆï¼šã€Šå¤§ç™½é²¨ã€‹çš„å¯¼æ¼”æ˜¯å²è’‚æ–‡Â·æ–¯çš®å°”ä¼¯æ ¼ã€‚\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# 4.å®šä¹‰ç¤ºä¾‹é€‰æ‹©å™¨\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # è¿™æ˜¯å¯ä¾›é€‰æ‹©çš„ç¤ºä¾‹åˆ—è¡¨\n",
    "    examples,\n",
    "    # è¿™æ˜¯ç”¨äºç”ŸæˆåµŒå…¥çš„åµŒå…¥ç±»ï¼Œç”¨äºè¡¡é‡è¯­ä¹‰ç›¸ä¼¼æ€§\n",
    "    embeddings_model,\n",
    "    # è¿™æ˜¯ç”¨äºå­˜å‚¨åµŒå…¥å¹¶è¿›è¡Œç›¸ä¼¼æ€§æœç´¢çš„ VectorStore ç±»\n",
    "    Chroma,\n",
    "    # è¿™æ˜¯è¦ç”Ÿæˆçš„ç¤ºä¾‹æ•°é‡\n",
    "    k=1,\n",
    ")\n",
    "\n",
    "# é€‰æ‹©ä¸è¾“å…¥æœ€ç›¸ä¼¼çš„ç¤ºä¾‹\n",
    "question = \"ç›ä¸½Â·é²å°”Â·åç››é¡¿çš„çˆ¶äº²æ˜¯è°?\"\n",
    "selected_examples = example_selector.select_examples({\"question\": question})\n",
    "print(f\"ä¸è¾“å…¥æœ€ç›¸ä¼¼çš„ç¤ºä¾‹ï¼š{selected_examples}\")\n",
    "\n",
    "# for example in selected_examples:\n",
    "#     print(\"\\n\")\n",
    "#     for k, v in example.items():\n",
    "#         print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4d0cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ç»“åˆå°‘é‡ç¤ºä¾‹ç»™å¤§æ¨¡å‹\n",
    "# 1.å¯¼å…¥ç›¸å…³åŒ…\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 2.å®šä¹‰ç¤ºä¾‹æç¤ºè¯æ¨¡ç‰ˆ\n",
    "example_prompt = PromptTemplate.from_template(\n",
    "    template=\"Input: {input}\\nOutput: {output}\",\n",
    ")\n",
    "\n",
    "# 3.åˆ›å»ºä¸€ä¸ªç¤ºä¾‹æç¤ºè¯æ¨¡ç‰ˆ\n",
    "examples = [\n",
    "    {\"input\": \"é«˜å…´\", \"output\": \"æ‚²ä¼¤\"},\n",
    "    {\"input\": \"é«˜\", \"output\": \"çŸ®\"},\n",
    "    {\"input\": \"é•¿\", \"output\": \"çŸ­\"},\n",
    "    {\"input\": \"ç²¾åŠ›å……æ²›\", \"output\": \"æ— ç²¾æ‰“é‡‡\"},\n",
    "    {\"input\": \"é˜³å…‰\", \"output\": \"é˜´æš—\"},\n",
    "    {\"input\": \"ç²—ç³™\", \"output\": \"å…‰æ»‘\"},\n",
    "    {\"input\": \"å¹²ç‡¥\", \"output\": \"æ½®æ¹¿\"},\n",
    "    {\"input\": \"å¯Œè£•\", \"output\": \"è´«ç©·\"},\n",
    "]\n",
    "\n",
    "# 4.å®šä¹‰åµŒå…¥æ¨¡å‹\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "# 5.åˆ›å»ºè¯­ä¹‰ç›¸ä¼¼æ€§ç¤ºä¾‹é€‰æ‹©å™¨\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples,\n",
    "    embeddings,\n",
    "    FAISS,\n",
    "    k=2,\n",
    ")\n",
    "#æˆ–è€…\n",
    "#example_selector = SemanticSimilarityExampleSelector(\n",
    "#    examples,\n",
    "#    embeddings,\n",
    "#    FAISS,\n",
    "#    k=2\n",
    "#)\n",
    "\n",
    "# 6.å®šä¹‰å°æ ·æœ¬æç¤ºè¯æ¨¡ç‰ˆ\n",
    "similar_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"ç»™å‡ºæ¯ä¸ªè¯ç»„çš„åä¹‰è¯\",\n",
    "    suffix=\"Input: {word}\\nOutput:\",\n",
    "    input_variables=[\"word\"],\n",
    ")\n",
    "\n",
    "response = similar_prompt.invoke({\"word\":\"å¿§éƒ\"})\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5f5794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¿«ä¹\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "\n",
    "# 3\n",
    "example_prompt = PromptTemplate.from_template(\n",
    "  template = \"input: {input}\\noutput: {output}\"\n",
    ")\n",
    "# 2\n",
    "examples = [\n",
    "    {\"input\": \"é«˜å…´\", \"output\": \"æ‚²ä¼¤\"},\n",
    "    {\"input\": \"é«˜\", \"output\": \"çŸ®\"},\n",
    "    {\"input\": \"é•¿\", \"output\": \"çŸ­\"},\n",
    "    {\"input\": \"ç²¾åŠ›å……æ²›\", \"output\": \"æ— ç²¾æ‰“é‡‡\"},\n",
    "    {\"input\": \"é˜³å…‰\", \"output\": \"é˜´æš—\"},\n",
    "    {\"input\": \"ç²—ç³™\", \"output\": \"å…‰æ»‘\"},\n",
    "    {\"input\": \"å¹²ç‡¥\", \"output\": \"æ½®æ¹¿\"},\n",
    "    {\"input\": \"å¯Œè£•\", \"output\": \"è´«ç©·\"},\n",
    "]\n",
    "\n",
    "# 4.å®šä¹‰åµŒå…¥æ¨¡å‹\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "# 5. è¯­ä¹‰é€‰æ‹©å™¨\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "  examples,\n",
    "  embeddings,\n",
    "  FAISS,\n",
    "  k=2,\n",
    ")\n",
    "\n",
    "# 1\n",
    "similar_prompt = FewShotPromptTemplate(\n",
    "  example_selector=example_selector,\n",
    "  example_prompt=example_prompt,\n",
    "  prefix=\"ç»™å‡ºæ¯ä¸ªè¯ç»„çš„åä¹‰è¯\",\n",
    "  suffix=\"Input: {word}\\nOutput:\",\n",
    "  input_variables=[\"word\"],\n",
    ")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "response = chat_model.invoke(similar_prompt.invoke({\"word\":\"å¿§éƒ\"}))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f5e250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¸è¾“å…¥æœ€ç›¸ä¼¼çš„ç¤ºä¾‹ï¼š[{'input': 'é«˜å…´', 'output': 'æ‚²ä¼¤'}, {'input': 'ç²¾åŠ›å……æ²›', 'output': 'æ— ç²¾æ‰“é‡‡'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "\n",
    "# 3\n",
    "example_prompt = PromptTemplate.from_template(\n",
    "  template = \"input: {input}\\noutput: {output}\"\n",
    ")\n",
    "# 2\n",
    "examples = [\n",
    "    {\"input\": \"é«˜å…´\", \"output\": \"æ‚²ä¼¤\"},\n",
    "    {\"input\": \"é«˜\", \"output\": \"çŸ®\"},\n",
    "    {\"input\": \"é•¿\", \"output\": \"çŸ­\"},\n",
    "    {\"input\": \"ç²¾åŠ›å……æ²›\", \"output\": \"æ— ç²¾æ‰“é‡‡\"},\n",
    "    {\"input\": \"é˜³å…‰\", \"output\": \"é˜´æš—\"},\n",
    "    {\"input\": \"ç²—ç³™\", \"output\": \"å…‰æ»‘\"},\n",
    "    {\"input\": \"å¹²ç‡¥\", \"output\": \"æ½®æ¹¿\"},\n",
    "    {\"input\": \"å¯Œè£•\", \"output\": \"è´«ç©·\"},\n",
    "]\n",
    "\n",
    "# 4.å®šä¹‰åµŒå…¥æ¨¡å‹\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "# 5. è¯­ä¹‰é€‰æ‹©å™¨\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "  examples,\n",
    "  embeddings,\n",
    "  # æˆ‘è¯•äº†å¦‚æœç”¨Chromaç»“æœä¼šå\n",
    "  FAISS,\n",
    "  k=2,\n",
    ")\n",
    "\n",
    "# 1\n",
    "similar_prompt = FewShotPromptTemplate(\n",
    "  example_selector=example_selector,\n",
    "  example_prompt=example_prompt,\n",
    "  prefix=\"ç»™å‡ºæ¯ä¸ªè¯ç»„çš„åä¹‰è¯\",\n",
    "  suffix=\"Input: {word}\\nOutput:\",\n",
    "  input_variables=[\"word\"],\n",
    ")\n",
    "\n",
    "# similar_prompt.invoke({\"word\":\"å¿§éƒ\"})\n",
    "# print(example_selector)\n",
    "# for _ in example_selector:\n",
    "#     print(_)\n",
    "\n",
    "# 4.å®šä¹‰ç¤ºä¾‹é€‰æ‹©å™¨\n",
    "# example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "#     # è¿™æ˜¯å¯ä¾›é€‰æ‹©çš„ç¤ºä¾‹åˆ—è¡¨\n",
    "#     examples,\n",
    "#     # è¿™æ˜¯ç”¨äºç”ŸæˆåµŒå…¥çš„åµŒå…¥ç±»ï¼Œç”¨äºè¡¡é‡è¯­ä¹‰ç›¸ä¼¼æ€§\n",
    "#     embeddings_model,\n",
    "#     # è¿™æ˜¯ç”¨äºå­˜å‚¨åµŒå…¥å¹¶è¿›è¡Œç›¸ä¼¼æ€§æœç´¢çš„ VectorStore ç±»\n",
    "#     Chroma,\n",
    "#     # è¿™æ˜¯è¦ç”Ÿæˆçš„ç¤ºä¾‹æ•°é‡\n",
    "#     k=1,\n",
    "# )\n",
    "\n",
    "# é€‰æ‹©ä¸è¾“å…¥æœ€ç›¸ä¼¼çš„ç¤ºä¾‹\n",
    "input = \"å¼€å¿ƒ\"\n",
    "# è¾“å…¥å­—å…¸\n",
    "selected_examples = example_selector.select_examples({\"input\": input})\n",
    "print(f\"ä¸è¾“å…¥æœ€ç›¸ä¼¼çš„ç¤ºä¾‹ï¼š{selected_examples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9dbcd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
