{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acf8bb2d",
   "metadata": {},
   "source": [
    "# 1. 对话模型中Message使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7137e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准的使用\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "# 前提：加载配置文件\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY1\")\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "\n",
    "# 1、获取对话模型\n",
    "chat_model = ChatOpenAI(\n",
    "    # api_key=,\n",
    "    # base_url=,\n",
    "    model_name=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "# 2、调用对话模型\n",
    "response = chat_model.invoke(\"帮我解释一下什么是langchain?\")\n",
    "\n",
    "# 3、处理响应数据\n",
    "# print(response)\n",
    "print(response.content)\n",
    "print(type(response))  #<class 'langchain_core.messages.ai.AIMessage'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e22716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "system_message = SystemMessage(content=\"你是一个英语教学方向的专家\")\n",
    "human_message = HumanMessage(content=\"帮我制定一个英语六级学习的计划\")\n",
    "\n",
    "messages = [system_message, human_message]\n",
    "\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e19e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "system_message = SystemMessage(\n",
    "    content=\"你是一个英语教学方向的专家\",\n",
    "    additional_kwargs={\"tool\":\"invoke_func1\"}\n",
    ")\n",
    "human_message = HumanMessage(content=\"帮我制定一个英语六级学习的计划\")\n",
    "\n",
    "messages = [system_message, human_message]\n",
    "\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826beb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatMedssage平时用的不多\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    ChatMessage\n",
    ")\n",
    "\n",
    "# 创建不同类型的消息\n",
    "system_message = SystemMessage(content=\"你是一个专业的数据科学家\")\n",
    "human_message = HumanMessage(content=\"解释一下随机森林算法\")\n",
    "ai_message = AIMessage(content=\"随机森林是一种集成学习方法...\")\n",
    "custom_message = ChatMessage(role=\"analyst\", content=\"补充一点关于超参数调优的信息\")\n",
    "\n",
    "print(system_message.content)\n",
    "print(human_message.content)\n",
    "print(ai_message.content)\n",
    "print(custom_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a837c24d",
   "metadata": {},
   "source": [
    "# 2. 多轮对话和上下文记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b1923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY1\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "\tmodel=\"gpt-4o-mini\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad04663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大模型本身是没有上下文记忆能力，能力其实就是一个函数\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "sys_message = SystemMessage(\n",
    "    content=\"我是一个人工智能的助手，我的名字叫小智\",\n",
    ")\n",
    "human_message = HumanMessage(content=\"猫王是一只猫吗？\")\n",
    "\n",
    "messages = [sys_message, human_message]\n",
    "\n",
    "#调用大模型，传入messages\n",
    "response = chat_model.invoke(messages)\n",
    "# print(response.content)\n",
    "\n",
    "\n",
    "response1 = chat_model.invoke(\"你叫什么名字？\")\n",
    "print(response1.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e8e79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "sys_message = SystemMessage(\n",
    "    content=\"我是一个人工智能的助手，我的名字叫小智\",\n",
    ")\n",
    "human_message = HumanMessage(content=\"猫王是一只猫吗？\")\n",
    "human_message1 = HumanMessage(content=\"你叫什么名字？\")\n",
    "\n",
    "messages = [sys_message, human_message,human_message1]\n",
    "\n",
    "#调用大模型，传入messages\n",
    "response = chat_model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eb2373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "sys_message = SystemMessage(\n",
    "    content=\"我是一个人工智能的助手，我的名字叫小智\",\n",
    ")\n",
    "human_message = HumanMessage(content=\"猫王是一只猫吗？\")\n",
    "\n",
    "sys_message1 = SystemMessage(\n",
    "    content=\"我可以做很多事情，有需要就找我吧\",\n",
    ")\n",
    "\n",
    "human_message1 = HumanMessage(content=\"你叫什么名字？\")\n",
    "\n",
    "messages = [sys_message, human_message,sys_message1,human_message1]\n",
    "\n",
    "#调用大模型，传入messages\n",
    "response = chat_model.invoke(messages)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b10975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# 第1组\n",
    "sys_message = SystemMessage(\n",
    "    content=\"我是一个人工智能的助手，我的名字叫小智\",\n",
    ")\n",
    "human_message = HumanMessage(content=\"猫王是一只猫吗？\")\n",
    "\n",
    "messages = [sys_message, human_message]\n",
    "\n",
    "# 第2组\n",
    "sys_message1 = SystemMessage(\n",
    "    content=\"我可以做很多事情，有需要就找我吧\",\n",
    ")\n",
    "\n",
    "human_message1 = HumanMessage(content=\"你叫什么名字？\")\n",
    "\n",
    "messages1 = [sys_message1,human_message1]\n",
    "\n",
    "#调用大模型，传入messages\n",
    "response = chat_model.invoke(messages)\n",
    "# print(response.content)\n",
    "\n",
    "response = chat_model.invoke(messages1)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2b21a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"我是一个人工智能助手，我的名字叫小智\"),\n",
    "    HumanMessage(content=\"人工智能英文怎么说？\"),\n",
    "    AIMessage(content=\"AI\"),\n",
    "    HumanMessage(content=\"你叫什么名字\"),\n",
    "]\n",
    "\n",
    "messages1 = [\n",
    "    SystemMessage(content=\"我是一个人工智能助手，我的名字叫小智\"),\n",
    "    HumanMessage(content=\"很高兴认识你\"),\n",
    "    AIMessage(content=\"我也很高兴认识你\"),\n",
    "    HumanMessage(content=\"你叫什么名字\"),\n",
    "]\n",
    "\n",
    "messages2 = [\n",
    "    SystemMessage(content=\"我是一个人工智能助手，我的名字叫小智\"),\n",
    "    HumanMessage(content=\"人工智能英文怎么说？\"),\n",
    "    AIMessage(content=\"AI\"),\n",
    "    HumanMessage(content=\"你叫什么名字\"),\n",
    "]\n",
    "\n",
    "chat_model.invoke(messages2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee80440a",
   "metadata": {},
   "source": [
    "# 3. 调用模型方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06316c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY1\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "\n",
    "#初始化大模型\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 创建消息\n",
    "messages = [HumanMessage(content=\"你好，请介绍一下自己\")]\n",
    "\n",
    "# 非流式调用LLM获取响应\n",
    "response = chat_model.invoke(messages)\n",
    "\n",
    "# 打印响应内容\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a796cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "\n",
    "# 初始化大模型\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\",\n",
    "                        streaming=True  # 启用流式输出\n",
    "                        )\n",
    "\n",
    "# 创建消息\n",
    "messages = [HumanMessage(content=\"你好，请介绍一下自己\")]\n",
    "\n",
    "# 流式调用LLM获取响应\n",
    "print(\"开始流式输出：\")\n",
    "for chunk in chat_model.stream(messages):\n",
    "    # 逐个打印内容块\n",
    "    print(chunk.content, end=\"\", flush=True) # 刷新缓冲区 (无换行符，缓冲区未刷新，内容可能不会立即显示)\n",
    "\n",
    "print(\"\\n流式输出结束\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9033a758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='机器学习是一种人工智能（AI）的分支，旨在通过数据和算法使计算机系统能够自动学习和改进，而无需明确的编程指令。它的核心思想是，通过分析和识别数据中的模式，计算机能够从经验中学习，并基于这些学习作出预测或决策。\\n\\n机器学习通常可以分为几种主要类型：\\n\\n1. **监督学习（Supervised Learning）**：在这种方法中，模型在带有标签的数据集上进行训练，目的是学习输入与输出之间的映射关系。常见的应用包括分类（如垃圾邮件检测）和回归（如房价预测）。\\n\\n2. **无监督学习（Unsupervised Learning）**：与监督学习不同，无监督学习在没有标签的数据集上进行训练，目的是发现数据中的潜在结构或模式。常见的应用包括聚类（如客户细分）和降维（如主成分分析）。\\n\\n3. **半监督学习（Semi-Supervised Learning）**：这种方法结合了监督学习和无监督学习，使用少量带标签的数据和大量无标签的数据进行训练，常用于获取更好的模型性能。\\n\\n4. **强化学习（Reinforcement Learning）**：在这种类型的学习中，模型通过与环境的交互来学习，目的是最大化某种累积的奖励。它常用于游戏、机器人控制等领域。\\n\\n机器学习在多个领域得到了广泛应用，包括自然语言处理、计算机视觉、医疗诊断、金融预测等。它正在推动科技的进步，并改变了许多行业的运作方式。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 350, 'prompt_tokens': 30, 'total_tokens': 380, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'finish_reason': 'stop', 'logprobs': None}, id='run--b70fd968-7955-4850-92fc-e7808f5f9919-0', usage_metadata={'input_tokens': 30, 'output_tokens': 350, 'total_tokens': 380, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='AIGC（人工智能生成内容，Artificial Intelligence Generated Content）是指通过人工智能技术生成的各种类型的内容，包括文本、图像、音频和视频等。随着深度学习和自然语言处理等技术的发展，AIGC在创作、设计和媒体等领域越来越受到关注。\\n\\nAIGC的主要特点包括：\\n\\n1. **自动化生成**：AIGC可以通过算法和模型自动生成内容，减少了人工创作的时间和成本。\\n\\n2. **多样性**：AIGC可以生成不同风格和类型的内容，满足用户的多样化需求。\\n\\n3. **智能化**：通过机器学习，AIGC能够不断学习和优化，提升内容的质量和相关性。\\n\\n4. **应用广泛**：AIGC被广泛应用于新闻报道、在线营销、社交媒体、游戏开发、艺术创作等多个领域。\\n\\n例如，利用自然语言处理模型（如GPT系列）生成的文章，或者使用生成对抗网络（GAN）创建的图像和视频，都是AIGC的具体应用实例。\\n\\n尽管AIGC在提高生产效率和创作灵活性方面具有巨大的潜力，但也伴随着一些挑战，如版权问题、伦理问题和内容的真实性等。因此，在使用AIGC时，合理的监管和使用规范显得尤为重要。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 296, 'prompt_tokens': 31, 'total_tokens': 327, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'finish_reason': 'stop', 'logprobs': None}, id='run--9e67612c-dd48-4b92-a036-02e1744271cc-0', usage_metadata={'input_tokens': 31, 'output_tokens': 296, 'total_tokens': 327, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='大模型技术是指基于深度学习的人工智能模型，这些模型通常具有巨大的参数量和复杂的结构，能够处理和生成自然语言、图像、音频等多种类型的数据。以下是大模型技术的一些关键特征和应用：\\n\\n1. **规模庞大**：大模型通常包含数亿到数千亿个参数，这使得它们能够学习更复杂的模式和特征。\\n\\n2. **自监督学习**：许多大模型采用自监督学习的方式进行训练。这意味着模型在没有标签的情况下，通过预测输入数据的一部分来学习数据的结构。\\n\\n3. **迁移学习**：大模型在一个任务上训练后，可以通过微调（fine-tuning）快速适应其他相关任务，从而减少了对大量标注数据的需求。\\n\\n4. **多模态能力**：一些大模型能够同时处理不同类型的数据（如文本、图像和音频），这使得它们在多模态应用中表现出色。\\n\\n5. **应用广泛**：大模型技术在自然语言处理（NLP）、计算机视觉、语音识别、推荐系统等领域得到了广泛应用。例如，像GPT-3、BERT、DALL-E等模型都是大模型的代表，分别在文本生成、文本理解和图像生成方面表现突出。\\n\\n6. **计算资源需求高**：训练和运行大模型需要大量的计算资源和存储，这对硬件和算法的优化提出了挑战。\\n\\n大模型技术的快速发展正在推动人工智能的进步，使得机器能够更好地理解和生成复杂的人类语言和其他形式的数据。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 360, 'prompt_tokens': 31, 'total_tokens': 391, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'finish_reason': 'stop', 'logprobs': None}, id='run--23a05f39-6faf-4906-a50c-3e41c68dcee3-0', usage_metadata={'input_tokens': 31, 'output_tokens': 360, 'total_tokens': 391, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# 初始化大模型\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "messages1 = [SystemMessage(content=\"你是一位乐于助人的智能小助手\"),\n",
    "             HumanMessage(content=\"请帮我介绍一下什么是机器学习\"), ]\n",
    "\n",
    "messages2 = [SystemMessage(content=\"你是一位乐于助人的智能小助手\"),\n",
    "             HumanMessage(content=\"请帮我介绍一下什么是AIGC\"), ]\n",
    "\n",
    "messages3 = [SystemMessage(content=\"你是一位乐于助人的智能小助手\"),\n",
    "             HumanMessage(content=\"请帮我介绍一下什么是大模型技术\"), ]\n",
    "\n",
    "messages = [messages1, messages2, messages3]\n",
    "\n",
    "# 调用batch\n",
    "response = chat_model.batch(messages)\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b24b5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def call_model():\n",
    "    # 模拟同步API调用\n",
    "    print(\"开始调用模型...\")\n",
    "    time.sleep(5)  # 模拟调用等待,单位：秒\n",
    "    print(\"模型调用完成。\")\n",
    "\n",
    "def perform_other_tasks():\n",
    "    # 模拟执行其他任务\n",
    "    for i in range(5):\n",
    "        print(f\"执行其他任务 {i + 1}\")\n",
    "        time.sleep(1)  # 单位：秒\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    call_model()\n",
    "    perform_other_tasks()\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    return f\"总共耗时：{total_time}秒\"\n",
    "\n",
    "# 运行同步任务并打印完成时间\n",
    "main_time = main()\n",
    "print(main_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89532e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def async_call(llm):\n",
    "    await asyncio.sleep(5)  # 模拟异步操作\n",
    "    print(\"异步调用完成\")\n",
    "\n",
    "async def perform_other_tasks():\n",
    "    await asyncio.sleep(5)  # 模拟异步操作\n",
    "    print(\"其他任务完成\")\n",
    "\n",
    "async def run_async_tasks():\n",
    "    start_time = time.time()\n",
    "    await asyncio.gather(\n",
    "        async_call(None),  # 示例调用，使用None模拟LLM对象\n",
    "        perform_other_tasks()\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    return f\"总共耗时：{end_time - start_time}秒\"\n",
    "\n",
    "# # 正确运行异步任务的方式\n",
    "# if __name__ == \"__main__\":\n",
    "#     # 使用 asyncio.run() 来启动异步程序\n",
    "#     result = asyncio.run(run_async_tasks())\n",
    "#     print(result)\n",
    "\n",
    "\n",
    "# 在 Jupyter 单元格中直接调用\n",
    "result = await run_async_tasks()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e6148e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
